---
title: "Main analysis"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document:
    number_sections: yes
    fig_caption: yes
latex_engine: xelatex
link-citations: yes
linkcolor: blue
subparagraph: yes
citecolor: blue
urlcolor: blue
---

# Import pkgs and data 

```{r}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

# install pkgs

if (!require(pacman)) install.packages("pacman")

pacman::p_load(
  tidyverse,
  data.table,
  glue,
  purrr,
  broom,
  RColorBrewer, 
  corrplot, 
  PerformanceAnalytics,
  patchwork,
  here,
  estimatr, 
  DACF,
  ggpubr, 
  ggrepel,
  modelsummary, 
  marginaleffects,
  tidyhte, 
  fixest,
  glmnet,
  irr, # inter-coder reliability
  # text analysis
  tidytext,
  readtext,
  quanteda, 
  keyATM,
  stm
)
```

```{r}
ggplot2::theme_set(theme_minimal())

if (!require(stdidx)) devtools::install_github("graemeblair/stdidx")
library(stdidx)

if (!require(tidyhte)) devtools::install_github("ddimmery/tidyhte")
library(tidyhte)

source(here("functions", "utils.R"))

# raw data
df_string <- read_csv(here("raw_data", "HARV0049_OUTPUT_strings.csv"))
df_numeric <- read_csv(here("raw_data", "HARV0049_OUTPUT_numeric.csv"))

# processed data (content analysis)
coded_text1 <- read_csv(here("processed_data", "coded_text_JYK.csv"))
coded_text2 <- readxl::read_xlsx(here("processed_Data", "coded_text_Joan.xlsx")) %>%
  select(caseid, unsure, succeed, fail, contingent, misread)

coded_text <- left_join(coded_text1, coded_text2, 
          by = c("caseid")) 

coded_text <- coded_text %>% 
  mutate(across(is.numeric, .fns = ~replace_na(.,0))) 
```

# Inter-coder reliability test 

```{r}
irr_out <- reduce(list(get_int_coder(coded_text %>%
                select(unsure.x, unsure.y), "unsure"),
get_int_coder(coded_text %>%
                select(succeed.x, succeed.y), "succeed"),
get_int_coder(coded_text %>%
                select(fail.x, fail.y), "fail"),
get_int_coder(coded_text %>%
                select(contingent.x, contingent.y), "contingent"),
get_int_coder(coded_text %>%
                select(misread.x, misread.y), "misread")), bind_rows) 

modelsummary::datasummary_df(data = irr_out, 
                             output = here("outputs", "irr_tb.docx"))

modelsummary::datasummary_df(data = irr_out, 
                             output = "latex")
```

```{r}
coded_text <- coded_text %>%
  mutate(unsure = ifelse(unsure.x == unsure.y, unsure.x, NA), 
         succeed = ifelse(succeed.x == succeed.y, succeed.x, NA),
         fail = ifelse(fail.x == fail.y, fail.x, NA),
         contingent = ifelse(contingent.x == contingent.y, contingent.x, NA),
         misread = ifelse(misread.x == misread.y, misread.x, NA)) 
```

# Data summary 

## Categorical (Tables 1-2)

```{r}
datasummary_skim(df_string %>%
                   select(nat_origin, immigrant), 
                 type = "categorical",
                 output = here("outputs", "cat_data_summary.docx"))

datasummary_skim(df_string %>%
                   select(nat_origin, immigrant), 
                 type = "categorical",
                 output = "latex")
```

## Numeric 

```{r}
df_num_summary <- create_dummies(df_numeric) %>%
  select(chinese_origin, immigrant, DEM, GOP, college, female, age)

df_num_summary$hate_crime_treatment <- df_string$hate_crime_treatment

datasummary(modelsummary::All(df_num_summary) ~ hate_crime_treatment * (mean_no_na + std_no_na),
            fmt = 3,
            data = df_num_summary,
            output = here("outputs", "balance.docx"))

datasummary(modelsummary::All(df_num_summary) ~ hate_crime_treatment * (mean_no_na + std_no_na),
            fmt = 3, 
            data = df_num_summary,
            output = "latex")
```

# ATE

```{r}
# no scientific notation 
options(scipen = 999) 

# function to estimate ATE
estimate_ate <- function(dv) {
  out <- lm_robust(eval(as.symbol(dv)) ~ factor(hate_crime_treatment), data = df_numeric) %>%
    tidy() %>%
    filter(!str_detect(term, "Int")) %>%
    mutate(outcome = dv)
  
  return(out)
}

df_numeric %>%
    group_by(hate_crime_treatment) %>%
    summarize(r_mean = mean(racial_linked_fate), 
              e_mean = mean(ethnic_linked_fate))
```

```{r}
# correlation test
cor.test(df_numeric$ethnic_linked_fate, df_numeric$racial_linked_fate) 
# r = 0.72 [low 95% CI: 0.7, high 95% CI: 0.74, p.value < 0.0001]

cor_test_outs <- df_numeric %>%
  group_by(hate_crime_treatment) %>%
  summarize(cor = list(cor.test(ethnic_linked_fate, racial_linked_fate))) 

cor_test_outs$cor[[1]] # r = 0.72
cor_test_outs$cor[[2]] # r = 0.72
cor_test_outs$cor[[3]] # r = 0.68
cor_test_outs$cor[[4]] # r = 0.76

# 72% agreement 
df_numeric %>%
  mutate(re_agree = ifelse(ethnic_linked_fate == racial_linked_fate, 1, 0)) %>%
  pull(re_agree) %>%
  mean()

df_numeric <- df_numeric %>%
  mutate(re_linked_agree = ifelse(ethnic_linked_fate == racial_linked_fate, 1, 0))
```

```{r}
ate_outs <- purrr::map_dfr(list("chinese_virus", "racial_linked_fate", "ethnic_linked_fate", "re_linked_agree", "asian_racial_id", "asian_ethnic_id", "affirmative_action", "policy_crime"), estimate_ate) %>%
  mutate(term = case_when(
    str_detect(term, "4") ~ "Hate crime + political representation", 
    str_detect(term, "3") ~ "Hate crime + China threat", 
    str_detect(term, "2") ~ "Hate crime"
  )) 
```

## Linked fates (Figure 1)

```{r}
lf_plots <- ate_outs %>% 
  filter(str_detect(outcome, "linked_fate")) %>%
  mutate(outcome = case_when(
    str_detect(outcome, "ethnic") ~ "Ethnic linked fate",
    str_detect(outcome, "racial") ~ "Racial linked fate",
  )) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = outcome,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.4)) +
  coord_flip() +
  labs(
    #title = "Linked fates",
    x = "", 
    y = "Estimated ATE",
    col = "Outcome") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.7, end = 0.3) +
  geom_text_repel(position = position_dodge(width = 0.4)) +
  theme(legend.position = "bottom")

lf_plots

ggsave(here("outputs", "lf_plots.png"), 
       height = 6, 
       width = 8)
```

```{r}
df_num_desc <- df_numeric %>%
  pivot_longer(matches("_linked_fate")) %>%
  mutate(name = case_when(
    name == "ethnic_linked_fate" ~ "Ethnic linked fate",
    name == "racial_linked_fate" ~ "Racial linked fate"
  )) %>%
  mutate(treat_fct = case_when(
    hate_crime_treatment == 1 ~ "Control",
    hate_crime_treatment == 2 ~ "Hate crime",
    hate_crime_treatment == 3 ~ "Hate crime + China threat" ,
    hate_crime_treatment == 4 ~ "Hate crime + Political representation"
  ))
```

```{r}
t.test(df_numeric[df_numeric$hate_crime_treatment == 3,]$racial_linked_fate, 
       df_numeric[df_numeric$hate_crime_treatment == 4,]$racial_linked_fate) %>%
  tidy(conf.int = T)

t.test(df_numeric[df_numeric$hate_crime_treatment == 3,]$ethnic_linked_fate, 
       df_numeric[df_numeric$hate_crime_treatment == 4,]$ethnic_linked_fate) %>%
  tidy(conf.int = T)
```

```{r}
df_t2_plot <- df_num_desc %>%
  filter(hate_crime_treatment %in% c(1,2)) %>%
  ggplot(aes(x = value, 
             linetype = treat_fct,
             color = treat_fct,
             fill = treat_fct)) +
  geom_density(position = position_dodge(), 
               alpha = 0.3) +
  theme(legend.position = "bottom") +
  facet_wrap(~name, ncol = 2) +
  labs(x = "Response value", y = "Density",
       linetype = "Group",
       color = "Group",
       fill = "Group")

df_t3_plot <- df_num_desc %>%
  filter(hate_crime_treatment %in% c(1,3)) %>%
  ggplot(aes(x = value, 
             linetype = treat_fct,
             color = treat_fct,
             fill = treat_fct)) +
  geom_density(position = position_dodge(), 
               alpha = 0.3) +
  theme(legend.position = "bottom") +
  facet_wrap(~name, ncol = 2) +
  labs(x = "Response value", y = "Density",
       linetype = "Group",
       color = "Group",
       fill = "Group")

df_t4_plot <- df_num_desc %>%
  filter(hate_crime_treatment %in% c(1,4)) %>%
  ggplot(aes(x = value, 
             linetype = treat_fct,
             color = treat_fct,
             fill = treat_fct)) +
  geom_density(position = position_dodge(), 
               alpha = 0.3) +
  theme(legend.position = "bottom") +
  facet_wrap(~name, ncol = 2) +
  labs(x = "Response value", y = "Density",
       linetype = "Group",
       color = "Group",
       fill = "Group")
```

```{r}
density_plots <- df_t2_plot / df_t3_plot / df_t4_plot +
  plot_annotation(tag_levels = "a")

png(filename = here("outputs", "density_plots.png"),
    height = 10, 
    width = 8, 
    unit = "in", 
    res = 1200)

density_plots

dev.off()

ceiling_plot <- df_num_desc %>%
  group_by(treat_fct, name) %>%
  summarize(ceiling_pct = mean(value == 5),
            ci_lower = mean(value == 5) - 1.96 * sqrt(mean(value == 5) * (1 - mean(value == 5)) / n()),
            ci_upper = mean(value == 5) + 1.96 * sqrt(mean(value == 5) * (1 - mean(value == 5)) / n())) %>%
  ggplot(aes(x = treat_fct, y = ceiling_pct)) +
  geom_col() +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, position = position_dodge(0.9)) +
  coord_flip() +
  facet_wrap(~name) +
  labs(x = "",
       y = "Ceiling %") +
  scale_y_continuous(labels = scales::percent)

png(filename = here("outputs", "ceiling_effect.png"),
    height = 5, 
    width = 10, 
    unit = "in", 
    res = 1200)

ceiling_plot 

dev.off()

t.test(racial_linked_fate ~ factor(hate_crime_treatment), data = df_numeric %>%
          filter(hate_crime_treatment %in% c(2,4)))

t.test(ethnic_linked_fate ~ factor(hate_crime_treatment), data = df_numeric %>%
          filter(hate_crime_treatment %in% c(2,4)))
```

```{r}
lf_mods <- list(
  "Ethnic linked fate" = feols(ethnic_linked_fate ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Ethnic linked fate (weighted)" = feols(ethnic_linked_fate ~ factor(hate_crime_treatment), data = df_numeric, weights = ~weight, vcov = "hetero"),
  "Racial linked fate" = feols(racial_linked_fate ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Racial linked fate (weighted)" = feols(racial_linked_fate ~ factor(hate_crime_treatment), data = df_numeric, weights = ~weight, vcov = "hetero")
)

mad_cm <- c(
  "factor(hate_crime_treatment)4" = "Hate crime + political representation", 
  "factor(hate_crime_treatment)3" = "Hate crime + China threat", 
  "factor(hate_crime_treatment)2" = "Hate crime"
)
```

```{r}
modelsummary(lf_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             #coef_omit = "Intercept",
             output = here("outputs", "lf_mods.docx"))

modelsummary(lf_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             #coef_omit = "Intercept",
             output = "latex")
```

```{r}
lf_agree_mods <- list(
  "Racial and ethnic linked agreement" = feols(re_linked_agree ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Racial and ethnic linked agreement (weighted)" = feols(re_linked_agree ~ factor(hate_crime_treatment), data = df_numeric, weights = ~weight, vcov = "hetero")
)

mad_cm <- c(
  "factor(hate_crime_treatment)4" = "Hate crime + political representation", 
  "factor(hate_crime_treatment)3" = "Hate crime + China threat", 
  "factor(hate_crime_treatment)2" = "Hate crime"
)
```

```{r}
modelsummary(lf_agree_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             coef_omit = "Intercept",
             output = here("outputs", "lf_agree_mods.docx"))
```

```{r}
modelsummary(lf_agree_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             coef_omit = "Intercept",
             output = "latex")
```

## Completion time 

- T1: 68 words (428 characters)
avg: 13 secs 

- T2: 81 words (506 characters)
avg: 27 secs 

- T3: 97 words (627 characters)
avg: 24 secs

88 dropped 

```{r}
df_numeric$completion_time <- difftime(df_numeric$endtime, df_numeric$starttime, 
         unit = "mins") %>%
  as.numeric()

median(df_numeric$completion_time)

t.test(df_numeric[df_numeric$hate_crime_treatment == 3,]$completion_time, 
       df_numeric[df_numeric$hate_crime_treatment == 4,]$completion_time) %>%
  tidy(conf.int = T)
```

```{r}
df_numeric <- df_numeric %>%
  mutate(completion_time = ifelse(completion_time >= 60, NA, completion_time)) %>%
  mutate(time_missed = ifelse(is.na(completion_time), 1, 0))
```

```{r}
time_mods <- list(
  "Completion time" = feols(completion_time ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero")
  )

modelsummary(time_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             coef_omit = "Intercept",
             output = "gt")
```

## Other outcomes 

```{r}
other_mods <- list(
  "Chinese virus" = feols(chinese_virus ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Asian race ID" = feols(asian_racial_id ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Asian ethnic ID" = feols(asian_ethnic_id ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Affirmative action" = feols(affirmative_action ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero"),
  "Police funding" = feols(policy_crime ~ factor(hate_crime_treatment), data = df_numeric, vcov = "hetero")
)
```

```{r}
modelsummary(other_mods,
             estimate = c("{estimate}{stars} \n [{conf.low}, {conf.high}] \n p = {p.value}"),
             statistic = NULL,
             coef_map = mad_cm,
             #coef_omit = "Intercept",
             output = "latex")
```

## Identity importance 

```{r}
ate_outs %>% 
  filter(str_detect(outcome, "_id")) %>%
  mutate(outcome = case_when(
    str_detect(outcome, "racial") ~ "Racial ID importance", 
    str_detect(outcome, "ethnic") ~ "Ethnic ID importance"
  )) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = outcome,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.4)) +
  coord_flip() +
  labs(
    title = "ID importance",
    x = "", 
    y = "Estimated ATE",
    col = "Outcome") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.4)) 

ggsave(here("outputs", "id_plots.png"), 
       height = 6, 
       width = 8)
```

## Chinese virus 

```{r}
ate_outs %>% 
  filter(str_detect(outcome, "_virus")) %>%
  mutate(outcome = case_when(
    str_detect(outcome, "chinese") ~ "Chinese virus"
  )) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.4)) +
  coord_flip() +
  labs(
    title = "Chinese virus",
    x = "", 
    y = "Estimated ATE") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.4)) 

ggsave(here("outputs", "cv_plot.png"), 
       height = 6, 
       width = 8)
```

## Policy outcomes

```{r}
ate_outs %>% 
  filter(str_detect(outcome, "action|crime")) %>%
  mutate(outcome = case_when(
    str_detect(outcome, "action") ~ "Affirmative action",
    str_detect(outcome, "crime") ~ "Police funding"
  )) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = outcome,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.4)) +
  coord_flip() +
  labs(
    title = "Policy preferences",
    x = "", 
    y = "Estimated ATE",
    col = "Outcome") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.4)) 

ggsave(here("outputs", "policy_plots.png"), 
       height = 6, 
       width = 8)
```

# CATE

## Traditional approach

```{r}
# Function to compute bootstrap confidence interval for the median
bootstrap_ci <- function(x, alpha = 0.05, n_bootstrap = 1000) {
  bootstrapped_medians <- replicate(n_bootstrap, median(sample(x, replace = TRUE), na.rm = T))
  lower_ci <- quantile(bootstrapped_medians, alpha / 2)
  upper_ci <- quantile(bootstrapped_medians, 1 - alpha / 2)
  return(c(lower_ci, upper_ci))
}

# Chinese origin 
df_numeric$chinese_origin <- ifelse(df_numeric$nat_origin == 1, "Chinese", "Non-Chinese")

# Party ID
df_numeric$DEM <- ifelse(df_numeric$pid3 == 1 | df_numeric$pid7 %in% c(1, 3), "DEM", "Non-DEM")

df_numeric$GOP <- ifelse(df_numeric$pid3 == 3 | df_numeric$pid7 %in% c(7, 5), "GOP", "Non-GOP")

# Immigrant
df_numeric$immigrant <- ifelse(df_numeric$immigrant %in% c(1, 2), "Immigrant", "Non-immigrant")

# College
df_numeric$college <- ifelse(df_numeric$educ %in% c(5:6), "College", "Non-college")

# Male
df_numeric$female <- ifelse(df_numeric$gender4 == 2, "Female", "Else")

# Income 
mean(df_numeric$faminc_new == 97) # 8% of the respondents stated that they didn't want to say about their family income 

df_numeric$faminc_new[df_numeric$faminc_new == 97] <- NA

median(df_numeric$faminc_new, na.rm = T) # $80,000 - $99,999

df_numeric$high_income <- ifelse(df_numeric$faminc_new > median(df_numeric$faminc_new, na.rm = T), "High", "Median and Low")
```

```{r}
# China threat index 
df_numeric$china_threat_index <- idx_mean(df_numeric$china_threat_1_rule, df_numeric$china_threat_2_rule, df_numeric$china_threat_3_rule)

# Index binaries
df_numeric$china_threatend_high <- ifelse(df_numeric$china_threat_index > median(df_numeric$china_threat_index), "High", "Median and Low")

# Non-index binaries
df_numeric$china_threatend_high_econ <- ifelse(df_numeric$china_threat_1_rule > median(df_numeric$china_threat_1_rule), "High", "Median and Low")

df_numeric$china_threatend_high_security <- ifelse(df_numeric$china_threat_2_rule > median(df_numeric$china_threat_2_rule), "High", "Median and Low")

df_numeric$china_threatend_high_democracy <- ifelse(df_numeric$china_threat_3_rule > median(df_numeric$china_threat_3_rule), "High", "Median and Low")
```

```{r}
df_numeric$newsint[df_numeric$newsint == 7] <- NA  # political interest 

df_numeric$pol_interest <- (5 - df_numeric$newsint)
```

```{r}
df_num_summary_threatened <- create_dummies(df_numeric) %>%
  select(china_threatend_high, china_threat_1_rule, china_threat_2_rule, china_threat_3_rule, chinese_origin, immigrant, DEM, GOP, college, female, age,
         pol_interest)

datasummary_balance(~china_threatend_high, 
                    data = df_num_summary_threatened,
                    fmt = fmt_decimal(digits = 2, pdigits = 3), 
                    dinm_statistic = "p.value", 
                    stars = TRUE, 
                    output = "latex")
```

```{r}
df_numeric %>%
  pivot_longer(matches("_threat_")) %>%
  group_by(name) %>%
  summarize(
    median_word = median(value),
    lower_ci = bootstrap_ci(value)[1],
    upper_ci = bootstrap_ci(value)[2]
  )

df_numeric %>%
  pivot_longer(matches("_threat_")) %>%
  group_by(DEM, name) %>%
  summarize(
    median_word = median(value),
    lower_ci = bootstrap_ci(value)[1],
    upper_ci = bootstrap_ci(value)[2]
  )
```

```{r}
cn_threat_perception_plot <- df_numeric %>%
  #select(-china_threat_index) %>%
  pivot_longer(matches("_threat_")) %>%
  mutate(name = case_when(
    name == "china_threat_index" ~ "Index variable",
    name == "china_threat_1_rule" ~ "Economic threat",
    name == "china_threat_2_rule" ~ "Security threat",
    name == "china_threat_3_rule" ~ "Democracy threat"
  )) %>%
  mutate(name = factor(name, levels = c("Economic threat", "Security threat", "Democracy threat", "Index variable"))) %>%
  ggplot(aes(x = value)) +
  geom_density(alpha = 0.3) +
  labs(y = "Density",
       x = "China threat scale (0-100)",
       fill = "Dimensions") +
  facet_wrap(~name, ncol = 4) 

png(filename = here("outputs", "cn_threat_perception_plot.png"), 
    height = 6, 
    width = 10, 
    unit = "in", 
    res = 1200)

cn_threat_perception_plot

dev.off()
```

```{r}
png(filename = here("outputs", "cn_threat_perception_corr_plot.png"), 
    height = 10, 
    width = 12, 
    unit = "in", 
    res = 1200)

df_numeric %>%
  mutate(china_threatend_high = ifelse(china_threatend_high == "High", 1, 0)) %>%
  select(china_threat_1_rule, china_threat_2_rule, china_threat_3_rule, china_threat_index, china_threatend_high) %>%
  rename("China threat index" = china_threat_index,
         "China threat high perception" = china_threatend_high,
         "Economic threat" = china_threat_1_rule,
         "Security threat" = china_threat_2_rule,
         "Democracy threat" = china_threat_3_rule) %>%
  chart.Correlation(., histogram = TRUE, pch = "+")

dev.off()
```

```{r}
# Democracy conception
df_numeric$democracy_sub <- idx_mean(df_numeric$democracy_meaning_2 + df_numeric$democracy_meaning_4 + df_numeric$democracy_meaning_6)

df_numeric$democracy_cat <- ifelse(df_numeric$democracy_sub > median(df_numeric$democracy_sub), "High", "Median and Low")
```

```{r}
chinese_cate_plot <- bind_rows(
  df_numeric %>%
    group_by(chinese_origin) %>%
    nest_ols("racial_linked_fate"),
  df_numeric %>%
    group_by(chinese_origin) %>%
    nest_ols("ethnic_linked_fate")
  ) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = chinese_origin,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.2)) +
  coord_flip() +
  labs(
    title = "Chinese v Non-Chinese",
    x = "", 
    y = "Estimated ATE",
    col = "Subgroup") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.2)) +
  theme(legend.position = "right") +
  facet_wrap(~outcome)

china_threat_perc_plot <- bind_rows(
  df_numeric %>%
    group_by(china_threatend_high) %>%
    nest_ols("racial_linked_fate"),
  df_numeric %>%
    group_by(china_threatend_high) %>%
    nest_ols("ethnic_linked_fate")
  ) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = china_threatend_high,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.2)) +
  coord_flip() +
  labs(
    title = "Perceived China threat",
    x = "", 
    y = "Estimated ATE",
    col = "Subgroup") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.2)) +
  theme(legend.position = "right") +
  facet_wrap(~outcome)

dem_perc_plot <- bind_rows(
  df_numeric %>%
    group_by(democracy_cat) %>%
    nest_ols("racial_linked_fate"),
  df_numeric %>%
    group_by(democracy_cat) %>%
    nest_ols("ethnic_linked_fate")
  ) %>%
  ggplot(aes(x = term, y = estimate, ymax = conf.high, ymin = conf.low, col = democracy_cat,
             label = round(estimate, 2))) +
  geom_pointrange(position = position_dodge(width = 0.2)) +
  coord_flip() +
  labs(
    title = "Democracy perception",
    x = "", 
    y = "Estimated ATE",
    col = "Subgroup") +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed")  +
  scale_color_grey(start = 0.3, end = 0.7) +
  geom_text_repel(position = position_dodge(width = 0.2)) +
  theme(legend.position = "right") +
  facet_wrap(~outcome)

cate_rl_plots <- chinese_cate_plot / china_threat_perc_plot / dem_perc_plot + plot_annotation(tag_levels = "a")

cate_rl_plots

ggsave(plot = cate_rl_plots, 
       filename = here("outputs", "cate_rl_plots.png"), 
       height = 12, 
       width = 10)
```

## Double roubst learner

```{r}
set.seed(1234)

# racial linked fate
t2_rl_results <- get_db_rl_estimates(2)
t3_rl_results <- get_db_rl_estimates(3)
t4_rl_results <- get_db_rl_estimates(4)

# ethnic linked fate
t2_el_results <- get_db_el_estimates(2)
t3_el_results <- get_db_el_estimates(3)
t4_el_results <- get_db_el_estimates(4)
```

```{r}
rl_results <- reduce(list(
  t2_rl_results %>%
    mutate(treatment = "Hate crime"), 
  t3_rl_results %>%
    mutate(treatment = "Hate crime + China threat"), 
  t4_rl_results %>%
    mutate(treatment = "Hate crime + political representation")), bind_rows) %>%
  mutate(outcome = "Racial linked fate")
```

```{r}
el_results <- reduce(list(
  t2_el_results %>%
    mutate(treatment = "Hate crime"), 
  t3_el_results %>%
    mutate(treatment = "Hate crime + China threat"), 
  t4_el_results %>%
    mutate(treatment = "Hate crime + political representation")), bind_rows) %>%
  mutate(outcome = "Ethnic linked fate")
```

```{r}
results <- bind_rows(rl_results, el_results)
```

## Load 

```{r}
write_csv(results, here("processed_data", "cate_results.csv"))

results <- read_csv(here("processed_data", "cate_results.csv"))

View(results %>%
  filter(estimand == "MCATE") %>%
  arrange(outcome, treatment, desc(estimate)))
```

## Pooled (Figure 2)

### Long

```{r}
results_pooled <- results %>%
  filter(estimand == "MCATE")

# recode values in some dummy variables 
results_pooled <- recode_dummies(results_pooled) 
```

### Wide 

```{r}
level_list_rl <- t2_rl_results %>%
    filter(estimand == "MCATE") %>%
    pull(level)

term_list_rl <- t2_rl_results %>%
    filter(estimand == "MCATE") %>%
    pull(term)

level_list_el <- t2_el_results %>%
    filter(estimand == "MCATE") %>%
    pull(level)

term_list_el <- t2_el_results %>%
    filter(estimand == "MCATE") %>%
    pull(term)
```

```{r}
rp_wide <- bind_rows(data.frame(
  level = level_list_rl,
  term = term_list_rl,
  chilling_effect = pull_est(t2_rl_results) - pull_est(t3_rl_results),
  boosting_effect = pull_est(t4_rl_results) - pull_est(t2_rl_results)) %>%
  mutate(outcome = "Racial linked fate"),
  data.frame(
  level = level_list_el,
  term = term_list_el,
  chilling_effect = pull_est(t2_el_results) - pull_est(t3_el_results),
  boosting_effect = pull_est(t4_el_results) - pull_est(t2_el_results)
  ) %>%
  mutate(outcome = "Ethnic linked fate")
) 

rp_wide <- recode_dummies(rp_wide)

mean(rp_wide$chilling_effect)/mean(rp_wide$boosting_effect)
```

### Visualization 

```{r}
tr_string <- unique(results_pooled$treatment)

cate_sum <- results_pooled %>%
  filter(!str_detect(level, "Non-G|Non-D")) %>%
  mutate(significant = ifelse(estimate - 1.96 * std_error > 0, "Significant", "Non-significant")) %>%
  mutate(treatment_fct = case_when(
    treatment == tr_string[1] ~ paste("A. ", tr_string[1]),
    treatment == tr_string[2] ~ paste("B. ", tr_string[2]),
    treatment == tr_string[3] ~ paste("C. ", tr_string[3])
  )) 
```

```{r}
cate_sum %>%
  dplyr::group_by(treatment, outcome) %>%
  dplyr::count(significant) %>%
  ungroup() %>%
  dplyr::group_by(treatment, outcome) %>%
  mutate(freq = n/20) %>%
  View()
```

```{r}
cate_sum_wide <- cate_sum %>%
  left_join(rp_wide)

pooled_cate_plot <- cate_sum_wide %>%
  ggplot(aes(x = fct_reorder(level, estimate), 
             y = estimate,
             ymin = estimate - 1.96 * std_error,
             ymax = estimate + 1.96 * std_error,
             label = round(estimate, 2), 
             col = significant,
             shape = outcome)) +
  geom_pointrange(position = position_dodge(width = 0.2)) +
  #geom_text_repel(position = position_dodge(width = 0.2)) +
  coord_flip() +
  facet_wrap(~treatment_fct, ncol = 3, nrow = 1) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed") +
  labs(x = "",
       y = "Estimated CATE",
       shape = "Outcome",
       col = "Statistical significance") +
  theme(legend.position = "bottom") +
  scale_color_grey(start = 0.7, end = 0.3) 

pooled_cate_plot
```

## Save

```{r}
png(filename = here("outputs", "pooled_cate_plot.png"), 
    height = 8, 
    width = 14, 
    unit = "in", 
    res = 1200)

pooled_cate_plot

dev.off()
```

# Open-ended texts

## Descriptive statitics 

```{r}
df_string$word_count <- stringr::str_count(df_string$asian_open_ended_question)

df_string %>%
  summarize(
    median_word = median(word_count, na.rm = TRUE),
    lower_ci = bootstrap_ci(word_count)[1],
    upper_ci = bootstrap_ci(word_count)[2]
  )

df_string %>%
  group_by(hate_crime_treatment) %>%
  summarize(
    median_word = median(word_count, na.rm = TRUE),
    lower_ci = bootstrap_ci(word_count)[1],
    upper_ci = bootstrap_ci(word_count)[2]
  ) %>%
  datasummary_df(output = "latex")
```

```{r}
word_count_plot <- df_string %>%
  ggplot(aes(x = word_count)) +
  geom_histogram(bins = 100, alpha = 0.3) +
  geom_vline(xintercept = median(df_string$word_count, na.rm = T), 
             linetype = 2) +
  labs(x = "Word count", 
       y = "Frequency", 
       title = "The frequency of word counts in open-ended responses") +
  annotate("text", x = 500, y = 200, label = "The median word count is 44")

png(filename = here("outputs", "word_count.png"),
    height = 5, 
    width = 8, 
    unit = "in", 
    res = 1200)

word_count_plot

dev.off()
```

```{r}
my_stop_words <- bind_rows(stop_words, 
                           tibble(word = c("asian", "asians", "american", "americans"),
                                  lexicon = rep("custom", 4)))

# succeed, fail are frequent words

df_string %>%
  unnest_tokens(word, asian_open_ended_question) %>%
  anti_join(my_stop_words) %>%
  count(hate_crime_treatment, word, sort = TRUE) %>%
  head(n = 30) 

df_string_word_pct <- df_string %>%
  mutate(succeed = ifelse(str_detect(tolower(asian_open_ended_question), "succeed"), 1, 0)) %>%
  mutate(fail = ifelse(str_detect(tolower(asian_open_ended_question), "fail"), 1, 0)) %>%
  select(hate_crime_treatment, succeed, fail)

datasummary(All(df_string_word_pct) ~ hate_crime_treatment * (mean_no_na + std_no_na),
            data = df_string_word_pct,
            output = here("outputs", "balance_word_pct.docx"))
```

## Content analysis (Figure 3)

```{r}
coded_text %>%
  filter(!is.na(asian_open_ended_question)) %>% # n = 1,878, 94% response rate 
  filter(misread == 0) %>%
  summarize(mean(fail, na.rm = T))

coded_text$hate_crime_treatment[coded_text$hate_crime_treatment == "control"] <- "Control"
```

```{r}
coded_text_summary <- coded_text %>%
  mutate(text_responded = ifelse(!is.na(asian_open_ended_question) & misread == 0, "responded", "not_responded")) %>%
  mutate(text_responded = ifelse(is.na(text_responded), "not_responded", text_responded)) 

df_num_summary_with_case <- create_dummies(df_numeric) %>%
  select(caseid, chinese_origin, immigrant, DEM, GOP, college, female, age)

coded_text_meta_summary <- coded_text_summary %>%
  left_join(df_num_summary_with_case) %>%
  select(text_responded, chinese_origin, immigrant, DEM, GOP, college, female, age)

datasummary_balance(~text_responded, 
                    data = coded_text_meta_summary,
                    fmt = fmt_decimal(digits = 2, pdigits = 3), 
                    dinm_statistic = "p.value", 
                    stars = TRUE, 
                    output = "latex")
```

```{r}
ca_plot <- coded_text %>%
  filter(!is.na(asian_open_ended_question)) %>% # n = 1,878, 94% response rate 
  filter(misread == 0) %>% # n = 1,608
  group_by(hate_crime_treatment) %>%
  summarize(unsure_rate = mean(unsure, na.rm = T), 
            succeed_rate = mean(succeed, na.rm = T), 
            fail_rate = mean(fail, na.rm = T), 
            contingnet_rate = mean(contingent, na.rm = T)) %>%
  pivot_longer(matches("rate")) %>%
  mutate(name = case_when(
    str_detect(name, "unsure") ~ "Unsure: Confused about the notion of Asian American coalitions", 
    str_detect(name, "succeed") ~ "Succeed: Asian Americans would unite",
    str_detect(name, "fail") ~ "Fail: Asian Americans would not unite",
    str_detect(name, "conti") ~ "Contingent: Asian American coalition is contingent"
  )) %>%
  ggplot(aes(x = hate_crime_treatment, y = value)) +
  geom_col() +
  geom_errorbar(aes(ymin = value - 1.96*sd(value) / sqrt(length(value)),
                    ymax = value + 1.96*sd(value) / sqrt(length(value))),
                position = position_dodge(width = 0.4)) +
  geom_text(aes(label = paste0(round(value, 2)*100, "%")), nudge_y = 0.12) +
  facet_wrap(~name) +
  coord_flip() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "", 
       y = "Proportion of the responses",
       title = "Content analysis of open-ended responses",
       subtitle = "Excluding non- and misread-responses (n = 1,608)")
```

```{r}
png(filename = here("outputs", "content_analysis.png"),
    height = 7, 
    width = 10, 
    unit = "in", 
    res = 1200)

ca_plot

dev.off()
```

## keyATM

### Preprocess

```{r}
corpus <- coded_text %>%
  filter(!is.na(asian_open_ended_question)) %>% # n = 1,878, 94% response rate 
  filter(misread == 0) %>% # n = 1,636
  filter(fail == 1) %>%
  mutate(text = clean_text(asian_open_ended_question))
```

```{r}
key_corpus <- quanteda::corpus(corpus$text)

docvars(key_corpus, "hate_crime_treatment") <- corpus$hate_crime_treatment
```

```{r}
# Tokenize 
data_tokens <- tokens(key_corpus) 
```

### Document-term matrix

```{r}
data_dfm <- dfm(data_tokens) 
```

### KeyATM

```{r}
keyATM_docs <- keyATM_read(texts = data_dfm)

keywords <- list(
    
    "diverisy" = c("language", "culture", "history", "generation", "east", "south", "chinese", "indian", "japanese", "filipino", "korean", "class", "privilege", "agenda", "competition", "fight", "internal"),
    
    "political_agency" = c("assert", "voice", "silent", "stay", "vote", "participate", "leader"),
    
    "outside_support" = c("support", "resource", "media", "funding", "government", "white")
    
    )

key_viz <- visualize_keywords(docs = keyATM_docs, 
                              keywords = keywords)

key_viz

save_fig(key_viz, here("outputs", "keyword.png")) 
```

```{r}
# run many models 
many_models <- tibble(K = c(3:5)) %>%
               mutate(topic_model = map(K, ~stm(data_dfm, K = .)))

write_rds(many_models, here("outputs", "many_models.rds"))

#many_models <- read_rds(here("outputs", "many_models.rds"))
```

```{r}
k_search_diag <- visualize_diag(data_dfm, many_models)

ggsave(here("outputs", "k_search_diag.png"))
```

#### Static topic modeling (Figure 4)

```{r}
set.seed(1234)

out <- keyATM(docs = keyATM_docs,       # text input
              no_keyword_topics = 1,    # number of topics without keywords
              keywords = keywords,      # keywords
              model = "base",           # select the model
              options = list(seed = 250,
              store_theta = TRUE))

write_rds(out, here("outputs", "keyATM_out.rds"))

#out <- read_rds(here("outputs", "keyATM_out.rds"))

# theta = document-topic distribution 
out$theta <- round(out$theta, 0)

# sum 
sums <- c(sum(out$theta[,1]), sum(out$theta[,2]), sum(out$theta[,3]))
```

```{r}
topic_out <- tibble(topic_sums = sums,
                    names = c("Diversity", "Political agency", "Outside support")) %>%  
           mutate(prop = topic_sums / sum(topic_sums),
           prop = round(prop, 2))

topic_out %>% 
    ggplot(aes(x = fct_reorder(names, prop), y = prop)) +
    geom_col(position = "dodge") +
    scale_y_continuous(labels =    
    scales::percent_format(accuracy = 1)) +
    labs(x = "Topic name", 
         y = "Topic proportion",          
         title = "Topic-document distributions",
        subtitle = "Responses mentioned the reasons on why Asian Americans would fail to unite (n = 806)") +
   geom_text(aes(label = paste0(round(prop, 2)*100, "%")), nudge_y = 0.05) 

ggsave(here("outputs", "topic_modeling_static.png"))
```

#### Covariate topic modeling 

```{r}
# Extract covariates 
vars <- docvars(key_corpus)

vars_selected <- vars %>%
  select(hate_crime_treatment) %>%
  mutate(treatment = factor(hate_crime_treatment))

# Topic modeling 
covariate_out <- keyATM(docs = keyATM_docs,       # text input
              no_keyword_topics = 1,    # number of topics without keywords
              keywords = keywords,      # keywords
              model = "covariates",           # select the model
              model_settings = list(covariates_data = vars_selected,
                                    covariates_formula = ~ treatment),
              options = list(seed = 250, store_theta = TRUE))

covariates_info(covariate_out)
```

```{r}
# Predicted mean of the document-term distribution for intervention 
strata_topic_t1 <- by_strata_DocTopic(covariate_out, by_var = "treatmentHate Crime",
                                   labels = c("Control", "Hate Crime"))

strata_topic_t2 <- by_strata_DocTopic(covariate_out, by_var = "treatmentHate Crime + China Threat",
                                   labels = c("Control", "Hate Crime + China threat"))

strata_topic_t3 <- by_strata_DocTopic(covariate_out, by_var = "treatmentHate Crime + Political Representation",
                                   labels = c("Control", "Hate Crime + Political representation"))
```

```{r}
reduce(list(strata_topic_t1$tables$`Hate Crime`,
strata_topic_t2$tables$`Hate Crime + China threat`,
strata_topic_t3$tables$`Hate Crime + Political representation`), 
  bind_rows) %>%
  filter(TopicID != 4) %>%
  rename(Label = label) %>%
  ggplot(aes(x = Label, 
             y = Point, 
             ymin = Lower, 
             ymax = Upper,
             label = round(Point, 2))) +
  geom_pointrange() +
  facet_wrap(~Topic) +
  coord_flip() +
  geom_text(nudge_x = 0.1) +
  labs(x = "", y = "Marginal posterior mean of document-topic distribution")

ggsave(here("outputs", "covariate_topic_modeling.png"))
```